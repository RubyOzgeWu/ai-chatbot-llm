""" Postman å–®ç´” fastAPI """
from elasticsearch import Elasticsearch
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from dotenv import load_dotenv
import os

""" è¨­ç½®ç’°å¢ƒ """
# è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

# è®€å–ç’°å¢ƒè®Šæ•¸
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("âŒ ç¼ºå°‘ GOOGLE_API_KEY ç’°å¢ƒè®Šæ•¸ï¼Œè«‹ç¢ºèª .env è¨­å®šï¼")

# åˆ¤æ–·æ˜¯å¦åœ¨ Docker å®¹å™¨å…§é‹è¡Œ
RUNNING_IN_DOCKER = os.path.exists('/.dockerenv')

if RUNNING_IN_DOCKER:
    ELASTICSEARCH_HOST = os.getenv("ELASTICSEARCH_HOSTS", "http://elasticsearch:9200")
else:
    ELASTICSEARCH_HOST = os.getenv("ELASTICSEARCH_HOSTS_LOCAL", "http://localhost:9200")


# ç¢ºèªç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢ºè¼‰å…¥
# print(f"ğŸ” GOOGLE_API_KEY: {GOOGLE_API_KEY}")
# print(f"ğŸ” ELASTICSEARCH_HOST: {ELASTICSEARCH_HOST}")

""" é€£æ¥ Elasticsearch """
es = Elasticsearch(ELASTICSEARCH_HOST)

""" å‘é‡åŒ–æ¨¡å‹ """
embedding_model = SentenceTransformer("sentence-transformers/distiluse-base-multilingual-cased-v2")


# æ¸¬è©¦é€£æ¥
try:
    es.info()
    print("âœ… Elasticsearch é€£æ¥æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Elasticsearch: {e}")

""" å°å…¥ LLM æ¨¡å‹ """
genai.configure(api_key=GOOGLE_API_KEY)
model_name = "gemini-1.5-flash"  
llm = genai.GenerativeModel(model_name)


""" RAG å‘é‡æª¢ç´¢æ–¹æ³• """
from numpy import dot
from numpy.linalg import norm

def cosine_score(vec1, vec2):
    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))

def normalize_article(article_text):
    import re
    CHINESE_NUMERAL_MAP = {
        "é›¶": 0, "ä¸€": 1, "äºŒ": 2, "ä¸‰": 3, "å››": 4,
        "äº”": 5, "å…­": 6, "ä¸ƒ": 7, "å…«": 8, "ä¹": 9,
        "å": 10, "ç™¾": 100, "åƒ": 1000
    }

    def chinese_to_int(text):
        if text.isdigit():
            return int(text)
        result, tmp = 0, 0
        units = {"å": 10, "ç™¾": 100, "åƒ": 1000}
        for ch in text:
            if ch in units:
                if tmp == 0:
                    tmp = 1
                result += tmp * units[ch]
                tmp = 0
            else:
                tmp = CHINESE_NUMERAL_MAP.get(ch, 0)
        return result + tmp

    m = re.match(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶\d]+)æ¢", article_text)
    if not m:
        return article_text
    raw = m.group(1)
    if raw.isdigit():
        return f"ç¬¬{raw}æ¢"
    return f"ç¬¬{chinese_to_int(raw)}æ¢"

def retrieve_similar_docs(query, index=["ai_immigration-law_index", "ai_immigration-regulations_index", "ai_nationality-law_index"], top_k=3, use_reference_expansion=True):
    query_embedding = embedding_model.encode(query).tolist()

    search_body = {
        "size": top_k,
        "query": {
            "script_score": {
                "query": {"match_all": {}},
                "script": {
                    "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
                    "params": {"query_vector": query_embedding}
                }
            }
        }
    }

    try:
        if not es.indices.exists(index=index):
            print(f"âŒ éŒ¯èª¤ï¼šç´¢å¼• '{index}' ä¸å­˜åœ¨ï¼è«‹å…ˆå»ºç«‹ç´¢å¼•ä¸¦è¼‰å…¥æ•¸æ“šï¼")
            return []

        response = es.search(index=index, body=search_body)
        docs = [hit["_source"] for hit in response["hits"]["hits"]]

        if use_reference_expansion:
            extra_docs = []
            seen_keys = set((doc["name"], doc["number"]) for doc in docs)  # é¿å…é‡è¤‡
            for doc in docs:
                for ref in doc.get("reference_laws", []):
                    try:
                        normalized_article = normalize_article(ref["article"])
                        law_name = ref["law_name"]

                        ref_query = {
                            "query": {
                                "bool": {
                                    "must": [
                                        {"match": {"number": normalized_article}},
                                        {"match": {"name": law_name}}
                                    ]
                                }
                            }
                        }
                        ref_hits = es.search(index=index, body=ref_query)["hits"]["hits"]
                        for hit in ref_hits:
                            ref_doc = hit["_source"]
                            key = (ref_doc.get("name"), ref_doc.get("number"))
                            if key not in seen_keys:
                                extra_docs.append(ref_doc)
                                seen_keys.add(key)
                    except Exception as e:
                        print(f"âš  æ“´å……æŸ¥è©¢å¤±æ•—: {e}")

            all_docs = docs + extra_docs
            all_docs = sorted(
                all_docs,
                key=lambda d: cosine_score(d["embedding"], query_embedding),
                reverse=True
            )
            docs = all_docs[:top_k]

        return [
            {
                "æ³•è¦åç¨±": doc.get("name", ""),
                "ä¿®æ­£æ—¥æœŸ": doc.get("date", ""),
                "ç« ç¯€æ¨™é¡Œ": doc.get("chapter_title", ""),
                "æ¢è™Ÿ": doc.get("number", ""),
                "å…§å®¹": doc.get("content", "")
            }
            for doc in docs
        ]

    except Exception as e:
        print(f"âŒ Elasticsearch æŸ¥è©¢å¤±æ•—: {e}")
        return []

# def retrieve_similar_docs(query, index=["ai_immigration-law_index", "ai_immigration-regulations_index", "ai_nationality-law_index"], top_k=3):
#     query_embedding = embedding_model.encode(query).tolist()

#     search_body = {
#         "size": top_k,
#         "query": {
#             "script_score": {
#                 "query": {"match_all": {}},
#                 "script": {
#                     "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
#                     "params": {"query_vector": query_embedding}
#                 }
#             }
#         }
#     }

#     try:
#         if not es.indices.exists(index=index):
#             print(f"âŒ éŒ¯èª¤ï¼šç´¢å¼• '{index}' ä¸å­˜åœ¨ï¼è«‹å…ˆå»ºç«‹ç´¢å¼•ä¸¦è¼‰å…¥æ•¸æ“šï¼")
#             return []

#         response = es.search(index=index, body=search_body)

#         return [
#             {
#                 "æ³•è¦åç¨±": hit["_source"].get("name", ""),
#                 "ä¿®æ­£æ—¥æœŸ": hit["_source"].get("date", ""),
#                 "ç« ç¯€æ¨™é¡Œ": hit["_source"].get("chapter_title", ""),
#                 "æ¢è™Ÿ": hit["_source"].get("number", ""),
#                 "å…§å®¹": hit["_source"].get("content", ""),
#             }
#             for hit in response["hits"]["hits"]
#         ]

#     except Exception as e:
#         print(f"âŒ Elasticsearch æŸ¥è©¢å¤±æ•—: {e}")
#         return []

""" RAG  æª¢ç´¢ + ç”Ÿæˆå›æ‡‰ """   
def rag_fastapi(user_query):
    # RAG æª¢ç´¢
    docs = retrieve_similar_docs(user_query)
    print(docs)

    if not docs:
        return  {
            "answer": "æ‰¾ä¸åˆ°ç›¸é—œæ¢æ–‡ã€‚",
            "references": []
        }

    # RAG æœå°‹ 
    context = "\n\n".join([
        f"{doc['æ³•è¦åç¨±']}ï¼ˆ{doc['ä¿®æ­£æ—¥æœŸ']}ï¼‰\n{doc['ç« ç¯€æ¨™é¡Œ']} {doc['æ¢è™Ÿ']}\n{doc['å…§å®¹']}"
        for doc in docs
    ])

    prompt = f"æ ¹æ“šä»¥ä¸‹è³‡è¨Šå›ç­”å•é¡Œ:\n{context}\n\nå•é¡Œ: {user_query}"
    response = llm.generate_content(prompt)

    return {
      "answer": response.text
    }

